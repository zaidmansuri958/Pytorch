{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFacGJrrYsco",
        "outputId": "4027e05a-ed90-4afe-8f74-3bfc332da873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "metadata": {
        "id": "MRzxhUHqY0Dr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEucqgjAZkiq",
        "outputId": "75f308ae-7f49-4953-c276-4bd7efb72b50"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"\"\"About the Program\n",
        "What is the course fee for  Data Science Mentorship Program (DSMP 2023)\n",
        "The course follows a monthly subscription model where you have to make monthly payments of Rs 799/month.\n",
        "What is the total duration of the course?\n",
        "The total duration of the course is 7 months. So the total course fee becomes 799*7 = Rs 5600(approx.)\n",
        "What is the syllabus of the mentorship program?\n",
        "We will be covering the following modules:\n",
        "Python Fundamentals\n",
        "Python libraries for Data Science\n",
        "Data Analysis\n",
        "SQL for Data Science\n",
        "Maths for Machine Learning\n",
        "ML Algorithms\n",
        "Practical ML\n",
        "MLOPs\n",
        "Case studies\n",
        "You can check the detailed syllabus here - https://learnwith.campusx.in/courses/CampusX-Data-Science-Mentorship-Program-637339afe4b0615a1bbed390\n",
        "Will Deep Learning and NLP be a part of this program?\n",
        "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes all our sessions are recorded, so even if you miss a session you can go back and watch the recording.\n",
        "Where can I find the class schedule?\n",
        "Checkout this google sheet to see month by month time table of the course - https://docs.google.com/spreadsheets/d/16OoTax_A6ORAeCg4emgexhqqPv3noQPYKU7RJ6ArOzk/edit?usp=sharing.\n",
        "What is the time duration of all the live sessions?\n",
        "Roughly, all the sessions last 2 hours.\n",
        "What is the language spoken by the instructor during the sessions?\n",
        "Hinglish\n",
        "How will I be informed about the upcoming class?\n",
        "You will get a mail from our side before every paid session once you become a paid user.\n",
        "Can I do this course if I am from a non-tech background?\n",
        "Yes, absolutely.\n",
        "I am late, can I join the program in the middle?\n",
        "Absolutely, you can join the program anytime.\n",
        "If I join/pay in the middle, will I be able to see all the past lectures?\n",
        "Yes, once you make the payment you will be able to see all the past content in your dashboard.\n",
        "Where do I have to submit the task?\n",
        "You don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\n",
        "Will we do case studies in the program?\n",
        "Yes.\n",
        "Where can we contact you?\n",
        "You can mail us at nitish.campusx@gmail.com\n",
        "Payment/Registration related questions\n",
        "Where do we have to make our payments? Your YouTube channel or website?\n",
        "You have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.campusx.in/\n",
        "Can we pay the entire amount of Rs 5600 all at once?\n",
        "Unfortunately no, the program follows a monthly subscription model.\n",
        "What is the validity of monthly subscription? Suppose if I pay on 15th Jan, then do I have to pay again on 1st Feb or 15th Feb\n",
        "15th Feb. The validity period is 30 days from the day you make the payment. So essentially you can join anytime you don’t have to wait for a month to end.\n",
        "What if I don’t like the course after making the payment. What is the refund policy?\n",
        "You get a 7 days refund period from the day you have made the payment.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmail.com\n",
        "Post registration queries\n",
        "Till when can I view the paid videos on the website?\n",
        "This one is tricky, so read carefully. You can watch the videos till your subscription is valid. Suppose you have purchased subscription on 21st Jan, you will be able to watch all the past paid sessions in the period of 21st Jan to 20th Feb. But after 21st Feb you will have to purchase the subscription again.\n",
        "But once the course is over and you have paid us Rs 5600(or 7 installments of Rs 799) you will be able to watch the paid sessions till Aug 2024.\n",
        "Why lifetime validity is not provided?\n",
        "Because of the low course fee.\n",
        "Where can I reach out in case of a doubt after the session?\n",
        "You will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearance session\n",
        "If I join the program late, can I still ask past week doubts?\n",
        "Yes, just select past week doubt in the doubt clearance google form.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmai.com\n",
        "Certificate and Placement Assistance related queries\n",
        "What is the criteria to get the certificate?\n",
        "There are 2 criterias:\n",
        "You have to pay the entire fee of Rs 5600\n",
        "You have to attempt all the course assessments.\n",
        "I am joining late. How can I pay payment of the earlier months?\n",
        "You will get a link to pay fee of earlier months in your dashboard once you pay for the current month.\n",
        "I have read that Placement assistance is a part of this program. What comes under Placement assistance?\n",
        "This is to clarify that Placement assistance does not mean Placement guarantee. So we dont guarantee you any jobs or for that matter even interview calls. So if you are planning to join this course just for placements, I am afraid you will be disappointed. Here is what comes under placement assistance\n",
        "Portfolio Building sessions\n",
        "Soft skill sessions\n",
        "Sessions with industry mentors\n",
        "Discussion on Job hunting strategies\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "EkwMj0L8ZXDj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k16-Z38FZfs3",
        "outputId": "a2b6c029-6d9a-4a57-ef5c-0457dfa16512"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=word_tokenize(document.lower())"
      ],
      "metadata": {
        "id": "4EQ8AHDOaLbV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counter(tokens).keys()"
      ],
      "metadata": {
        "id": "8Anfcel3ah8A"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab={'<unk>':0}\n",
        "\n",
        "for token in Counter(tokens).keys():\n",
        "  if token not in vocab:\n",
        "    vocab[token]=len(vocab)\n",
        "\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-Frsz7IaPPd",
        "outputId": "11976a85-8319-431a-fa35-ae6ca6d72be0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<unk>': 0,\n",
              " 'about': 1,\n",
              " 'the': 2,\n",
              " 'program': 3,\n",
              " 'what': 4,\n",
              " 'is': 5,\n",
              " 'course': 6,\n",
              " 'fee': 7,\n",
              " 'for': 8,\n",
              " 'data': 9,\n",
              " 'science': 10,\n",
              " 'mentorship': 11,\n",
              " '(': 12,\n",
              " 'dsmp': 13,\n",
              " '2023': 14,\n",
              " ')': 15,\n",
              " 'follows': 16,\n",
              " 'a': 17,\n",
              " 'monthly': 18,\n",
              " 'subscription': 19,\n",
              " 'model': 20,\n",
              " 'where': 21,\n",
              " 'you': 22,\n",
              " 'have': 23,\n",
              " 'to': 24,\n",
              " 'make': 25,\n",
              " 'payments': 26,\n",
              " 'of': 27,\n",
              " 'rs': 28,\n",
              " '799/month': 29,\n",
              " '.': 30,\n",
              " 'total': 31,\n",
              " 'duration': 32,\n",
              " '?': 33,\n",
              " '7': 34,\n",
              " 'months': 35,\n",
              " 'so': 36,\n",
              " 'becomes': 37,\n",
              " '799': 38,\n",
              " '*': 39,\n",
              " '=': 40,\n",
              " '5600': 41,\n",
              " 'approx': 42,\n",
              " 'syllabus': 43,\n",
              " 'we': 44,\n",
              " 'will': 45,\n",
              " 'be': 46,\n",
              " 'covering': 47,\n",
              " 'following': 48,\n",
              " 'modules': 49,\n",
              " ':': 50,\n",
              " 'python': 51,\n",
              " 'fundamentals': 52,\n",
              " 'libraries': 53,\n",
              " 'analysis': 54,\n",
              " 'sql': 55,\n",
              " 'maths': 56,\n",
              " 'machine': 57,\n",
              " 'learning': 58,\n",
              " 'ml': 59,\n",
              " 'algorithms': 60,\n",
              " 'practical': 61,\n",
              " 'mlops': 62,\n",
              " 'case': 63,\n",
              " 'studies': 64,\n",
              " 'can': 65,\n",
              " 'check': 66,\n",
              " 'detailed': 67,\n",
              " 'here': 68,\n",
              " '-': 69,\n",
              " 'https': 70,\n",
              " '//learnwith.campusx.in/courses/campusx-data-science-mentorship-program-637339afe4b0615a1bbed390': 71,\n",
              " 'deep': 72,\n",
              " 'and': 73,\n",
              " 'nlp': 74,\n",
              " 'part': 75,\n",
              " 'this': 76,\n",
              " 'no': 77,\n",
              " ',': 78,\n",
              " 'both': 79,\n",
              " 'are': 80,\n",
              " 'not': 81,\n",
              " '’': 82,\n",
              " 's': 83,\n",
              " 'curriculum': 84,\n",
              " 'if': 85,\n",
              " 'i': 86,\n",
              " 'miss': 87,\n",
              " 'live': 88,\n",
              " 'session': 89,\n",
              " 'get': 90,\n",
              " 'recording': 91,\n",
              " 'yes': 92,\n",
              " 'all': 93,\n",
              " 'our': 94,\n",
              " 'sessions': 95,\n",
              " 'recorded': 96,\n",
              " 'even': 97,\n",
              " 'go': 98,\n",
              " 'back': 99,\n",
              " 'watch': 100,\n",
              " 'find': 101,\n",
              " 'class': 102,\n",
              " 'schedule': 103,\n",
              " 'checkout': 104,\n",
              " 'google': 105,\n",
              " 'sheet': 106,\n",
              " 'see': 107,\n",
              " 'month': 108,\n",
              " 'by': 109,\n",
              " 'time': 110,\n",
              " 'table': 111,\n",
              " '//docs.google.com/spreadsheets/d/16ootax_a6oraecg4emgexhqqpv3noqpyku7rj6arozk/edit': 112,\n",
              " 'usp=sharing': 113,\n",
              " 'roughly': 114,\n",
              " 'last': 115,\n",
              " '2': 116,\n",
              " 'hours': 117,\n",
              " 'language': 118,\n",
              " 'spoken': 119,\n",
              " 'instructor': 120,\n",
              " 'during': 121,\n",
              " 'hinglish': 122,\n",
              " 'how': 123,\n",
              " 'informed': 124,\n",
              " 'upcoming': 125,\n",
              " 'mail': 126,\n",
              " 'from': 127,\n",
              " 'side': 128,\n",
              " 'before': 129,\n",
              " 'every': 130,\n",
              " 'paid': 131,\n",
              " 'once': 132,\n",
              " 'become': 133,\n",
              " 'user': 134,\n",
              " 'do': 135,\n",
              " 'am': 136,\n",
              " 'non-tech': 137,\n",
              " 'background': 138,\n",
              " 'absolutely': 139,\n",
              " 'late': 140,\n",
              " 'join': 141,\n",
              " 'in': 142,\n",
              " 'middle': 143,\n",
              " 'anytime': 144,\n",
              " 'join/pay': 145,\n",
              " 'able': 146,\n",
              " 'past': 147,\n",
              " 'lectures': 148,\n",
              " 'payment': 149,\n",
              " 'content': 150,\n",
              " 'your': 151,\n",
              " 'dashboard': 152,\n",
              " 'submit': 153,\n",
              " 'task': 154,\n",
              " 'don': 155,\n",
              " 't': 156,\n",
              " 'provide': 157,\n",
              " 'with': 158,\n",
              " 'solutions': 159,\n",
              " 'self': 160,\n",
              " 'evaluate': 161,\n",
              " 'yourself': 162,\n",
              " 'contact': 163,\n",
              " 'us': 164,\n",
              " 'at': 165,\n",
              " 'nitish.campusx': 166,\n",
              " '@': 167,\n",
              " 'gmail.com': 168,\n",
              " 'payment/registration': 169,\n",
              " 'related': 170,\n",
              " 'questions': 171,\n",
              " 'youtube': 172,\n",
              " 'channel': 173,\n",
              " 'or': 174,\n",
              " 'website': 175,\n",
              " 'on': 176,\n",
              " 'link': 177,\n",
              " '//learnwith.campusx.in/': 178,\n",
              " 'pay': 179,\n",
              " 'entire': 180,\n",
              " 'amount': 181,\n",
              " 'unfortunately': 182,\n",
              " 'validity': 183,\n",
              " 'suppose': 184,\n",
              " '15th': 185,\n",
              " 'jan': 186,\n",
              " 'then': 187,\n",
              " 'again': 188,\n",
              " '1st': 189,\n",
              " 'feb': 190,\n",
              " 'feb.': 191,\n",
              " 'period': 192,\n",
              " '30': 193,\n",
              " 'days': 194,\n",
              " 'day': 195,\n",
              " 'essentially': 196,\n",
              " 'wait': 197,\n",
              " 'end': 198,\n",
              " 'like': 199,\n",
              " 'after': 200,\n",
              " 'making': 201,\n",
              " 'refund': 202,\n",
              " 'policy': 203,\n",
              " 'made': 204,\n",
              " 'living': 205,\n",
              " 'outside': 206,\n",
              " 'india': 207,\n",
              " 'should': 208,\n",
              " 'sending': 209,\n",
              " 'post': 210,\n",
              " 'registration': 211,\n",
              " 'queries': 212,\n",
              " 'till': 213,\n",
              " 'when': 214,\n",
              " 'view': 215,\n",
              " 'videos': 216,\n",
              " 'one': 217,\n",
              " 'tricky': 218,\n",
              " 'read': 219,\n",
              " 'carefully': 220,\n",
              " 'valid': 221,\n",
              " 'purchased': 222,\n",
              " '21st': 223,\n",
              " '20th': 224,\n",
              " 'but': 225,\n",
              " 'purchase': 226,\n",
              " 'over': 227,\n",
              " 'installments': 228,\n",
              " 'aug': 229,\n",
              " '2024.': 230,\n",
              " 'why': 231,\n",
              " 'lifetime': 232,\n",
              " 'provided': 233,\n",
              " 'because': 234,\n",
              " 'low': 235,\n",
              " 'reach': 236,\n",
              " 'out': 237,\n",
              " 'doubt': 238,\n",
              " 'fill': 239,\n",
              " 'form': 240,\n",
              " 'team': 241,\n",
              " '1': 242,\n",
              " 'clearance': 243,\n",
              " 'still': 244,\n",
              " 'ask': 245,\n",
              " 'week': 246,\n",
              " 'doubts': 247,\n",
              " 'just': 248,\n",
              " 'select': 249,\n",
              " 'gmai.com': 250,\n",
              " 'certificate': 251,\n",
              " 'placement': 252,\n",
              " 'assistance': 253,\n",
              " 'criteria': 254,\n",
              " 'there': 255,\n",
              " 'criterias': 256,\n",
              " 'attempt': 257,\n",
              " 'assessments': 258,\n",
              " 'joining': 259,\n",
              " 'earlier': 260,\n",
              " 'current': 261,\n",
              " 'that': 262,\n",
              " 'comes': 263,\n",
              " 'under': 264,\n",
              " 'clarify': 265,\n",
              " 'does': 266,\n",
              " 'mean': 267,\n",
              " 'guarantee': 268,\n",
              " 'dont': 269,\n",
              " 'any': 270,\n",
              " 'jobs': 271,\n",
              " 'matter': 272,\n",
              " 'interview': 273,\n",
              " 'calls': 274,\n",
              " 'planning': 275,\n",
              " 'placements': 276,\n",
              " 'afraid': 277,\n",
              " 'disappointed': 278,\n",
              " 'portfolio': 279,\n",
              " 'building': 280,\n",
              " 'soft': 281,\n",
              " 'skill': 282,\n",
              " 'industry': 283,\n",
              " 'mentors': 284,\n",
              " 'discussion': 285,\n",
              " 'job': 286,\n",
              " 'hunting': 287,\n",
              " 'strategies': 288}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3QK8wcAac2O",
        "outputId": "c8218844-56df-41bf-b120-e024e232fa47"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "289"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences=document.split('\\n')"
      ],
      "metadata": {
        "id": "StTe0BtZarDT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZionIhHeauu0",
        "outputId": "aa726971-04d2-49c0-97c4-6018fdee89af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indices(sentence,vocab):\n",
        "  numerical_sentence=[]\n",
        "\n",
        "  for token in sentence:\n",
        "    if token in vocab:\n",
        "      numerical_sentence.append(vocab[token])\n",
        "    else:\n",
        "      numerical_sentence.append(vocab['<unk>'])\n",
        "  return numerical_sentence\n"
      ],
      "metadata": {
        "id": "6W0Zy40NaxVz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_numerical_sentences=[]\n",
        "\n",
        "for sentence in input_sentences:\n",
        "  input_numerical_sentences.append(text_to_indices(word_tokenize(sentence.lower()),vocab))"
      ],
      "metadata": {
        "id": "4CclYcJThc36"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_numerical_sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8rHHuFkh2TB",
        "outputId": "80cfc787-b6be-4bac-ed67-82934da77a78"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_numerical_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgQzVM7ah3P_",
        "outputId": "02763d93-d422-45d2-f2d2-dd4ceac93d17"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence=[]\n",
        "\n",
        "for sentence in input_numerical_sentences:\n",
        "  for i in range(1,len(sentence)):\n",
        "    training_sequence.append(sentence[:i+1])"
      ],
      "metadata": {
        "id": "Cw5l8KUAh-o3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C_Yv5lwiS3w",
        "outputId": "8a1d98a2-e335-49ee-a3ad-ae1502f8ac63"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "942"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45Vq1OrxiVGG",
        "outputId": "5ed51029-f1bb-46be-e2e7-f7c7efb0893c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2], [1, 2, 3], [4, 5], [4, 5, 2], [4, 5, 2, 6]]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list=[]\n",
        "\n",
        "for sequence in training_sequence:\n",
        "  len_list.append(len(sequence))\n",
        "\n",
        "max(len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfVSNxs8iX92",
        "outputId": "6fb0ceda-5fe6-47e9-ecae-7856d5e47b51"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence=[]\n",
        "for sequence in training_sequence:\n",
        "  padded_training_sequence.append([0]*(max(len_list)-len(sequence))+sequence)"
      ],
      "metadata": {
        "id": "v8MHqdjxik9d"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(padded_training_sequence[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdP2TOdRi01f",
        "outputId": "b10d6413-6b7c-4e6e-f361-d5a2787e8324"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence=torch.tensor(padded_training_sequence,dtype=torch.long)"
      ],
      "metadata": {
        "id": "0BA-_nHkjFCk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30ULNPGcjSoM",
        "outputId": "f4c0ea33-1f9e-45a0-9a9e-62631ce6ecbf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   1,   2,   3],\n",
              "        [  0,   0,   0,  ...,   0,   4,   5],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ..., 285, 176, 286],\n",
              "        [  0,   0,   0,  ..., 176, 286, 287],\n",
              "        [  0,   0,   0,  ..., 286, 287, 288]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=padded_training_sequence[:,:-1]\n",
        "y=padded_training_sequence[:,-1]"
      ],
      "metadata": {
        "id": "WYObcKqVjTrz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0daTF02yjaOD",
        "outputId": "9fa7483b-9dee-4b03-9093-156f534b90c6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   0,   1],\n",
              "        [  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   0,   0,   4],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ...,   0, 285, 176],\n",
              "        [  0,   0,   0,  ..., 285, 176, 286],\n",
              "        [  0,   0,   0,  ..., 176, 286, 287]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kStt_k8Pja-L",
        "outputId": "007ca526-be6f-4e6c-96f1-0b604f31fbd3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2,   3,   5,   2,   6,   7,   8,   9,  10,  11,   3,  12,  13,  14,\n",
              "         15,   6,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  18,  26,\n",
              "         27,  28,  29,  30,   5,   2,  31,  32,  27,   2,   6,  33,  31,  32,\n",
              "         27,   2,   6,   5,  34,  35,  30,  36,   2,  31,   6,   7,  37,  38,\n",
              "         39,  34,  40,  28,  41,  12,  42,  30,  15,   5,   2,  43,  27,   2,\n",
              "         11,   3,  33,  45,  46,  47,   2,  48,  49,  50,  52,  53,   8,   9,\n",
              "         10,  54,   8,   9,  10,   8,  57,  58,  60,  59,  64,  65,  66,   2,\n",
              "         67,  43,  68,  69,  70,  50,  71,  72,  58,  73,  74,  46,  17,  75,\n",
              "         27,  76,   3,  33,  78,  74,  73,  72,  58,  79,  80,  81,  17,  75,\n",
              "         27,  76,   3,  82,  83,  84,  30,  85,  86,  87,  17,  88,  89,  33,\n",
              "         45,  86,  90,  17,  91,  27,   2,  89,  33,  93,  94,  95,  80,  96,\n",
              "         78,  36,  97,  85,  22,  87,  17,  89,  22,  65,  98,  99,  73, 100,\n",
              "          2,  91,  30,  65,  86, 101,   2, 102, 103,  33,  76, 105, 106,  24,\n",
              "        107, 108, 109, 108, 110, 111,  27,   2,   6,  69,  70,  50, 112,  33,\n",
              "        113,  30,   5,   2, 110,  32,  27,  93,   2,  88,  95,  33,  78,  93,\n",
              "          2,  95, 115, 116, 117,  30,   5,   2, 118, 119, 109,   2, 120, 121,\n",
              "          2,  95,  33,  45,  86,  46, 124,   1,   2, 125, 102,  33,  45,  90,\n",
              "         17, 126, 127,  94, 128, 129, 130, 131,  89, 132,  22, 133,  17, 131,\n",
              "        134,  30,  86, 135,  76,   6,  85,  86, 136, 127,  17, 137, 138,  33,\n",
              "         78, 139,  30, 136, 140,  78,  65,  86, 141,   2,   3, 142,   2, 143,\n",
              "         33,  78,  22,  65, 141,   2,   3, 144,  30,  86, 145, 142,   2, 143,\n",
              "         78,  45,  86,  46, 146,  24, 107,  93,   2, 147, 148,  33,  78, 132,\n",
              "         22,  25,   2, 149,  22,  45,  46, 146,  24, 107,  93,   2, 147, 150,\n",
              "        142, 151, 152,  30, 135,  86,  23,  24, 153,   2, 154,  33, 155,  82,\n",
              "        156,  23,  24, 153,   2, 154,  30,  44,  45, 157,  22, 158,   2, 159,\n",
              "         78,  22,  23,  24, 160, 161,   2, 154, 162,  30,  44, 135,  63,  64,\n",
              "        142,   2,   3,  33,  30,  65,  44, 163,  22,  33,  65, 126, 164, 165,\n",
              "        166, 167, 168, 170, 171, 135,  44,  23,  24,  25,  94,  26,  33, 151,\n",
              "        172, 173, 174, 175,  33,  23,  24,  25,  93, 151,  18,  26, 176,  94,\n",
              "        175,  30,  68,   5,   2, 177,   8,  94, 175,  69,  70,  50, 178,  44,\n",
              "        179,   2, 180, 181,  27,  28,  41,  93, 165, 132,  33,  77,  78,   2,\n",
              "          3,  16,  17,  18,  19,  20,  30,   5,   2, 183,  27,  18,  19,  33,\n",
              "        184,  85,  86, 179, 176, 185, 186,  78, 187, 135,  86,  23,  24, 179,\n",
              "        188, 176, 189, 190, 174, 185, 190, 191,   2, 183, 192,   5, 193, 194,\n",
              "        127,   2, 195,  22,  25,   2, 149,  30,  36, 196,  22,  65, 141, 144,\n",
              "         22, 155,  82, 156,  23,  24, 197,   8,  17, 108,  24, 198,  30,  85,\n",
              "         86, 155,  82, 156, 199,   2,   6, 200, 201,   2, 149,  30,   4,   5,\n",
              "          2, 202, 203,  33,  90,  17,  34, 194, 202, 192, 127,   2, 195,  22,\n",
              "         23, 204,   2, 149,  30, 136, 205, 206, 207,  73,  86, 136,  81, 146,\n",
              "         24,  25,   2, 149, 176,   2, 175,  78,   4, 208,  86, 135,  33,  23,\n",
              "         24, 163, 164, 109, 209,  17, 126, 165, 166, 167, 168, 211, 212, 214,\n",
              "         65,  86, 215,   2, 131, 216, 176,   2, 175,  33, 217,   5, 218,  78,\n",
              "         36, 219, 220,  30,  22,  65, 100,   2, 216, 213, 151,  19,   5, 221,\n",
              "         30, 184,  22,  23, 222,  19, 176, 223, 186,  78,  22,  45,  46, 146,\n",
              "         24, 100,  93,   2, 147, 131,  95, 142,   2, 192,  27, 223, 186,  24,\n",
              "        224, 191, 225, 200, 223, 190,  22,  45,  23,  24, 226,   2,  19, 188,\n",
              "         30, 132,   2,   6,   5, 227,  73,  22,  23, 131, 164,  28,  41,  12,\n",
              "        174,  34, 228,  27,  28,  38,  15,  22,  45,  46, 146,  24, 100,   2,\n",
              "        131,  95, 213, 229,   0,  30, 232, 183,   5,  81, 233,  33,  27,   2,\n",
              "        235,   6,   7,  30,  65,  86, 236, 237, 142,  63,  27,  17, 238, 200,\n",
              "          2,  89,  33,  45,  23,  24, 239,  17, 105, 240, 233, 142, 151, 152,\n",
              "         73,  94, 241,  45, 163,  22,   8,  17, 242, 176, 242, 238, 243,  89,\n",
              "         86, 141,   2,   3, 140,  78,  65,  86, 244, 245, 147, 246, 247,  33,\n",
              "         78, 248, 249, 147, 246, 238, 142,   2, 238, 243, 105, 240,  30, 136,\n",
              "        205, 206, 207,  73,  86, 136,  81, 146,  24,  25,   2, 149, 176,   2,\n",
              "        175,  78,   4, 208,  86, 135,  33,  23,  24, 163, 164, 109, 209,  17,\n",
              "        126, 165, 166, 167, 250,  73, 252, 253, 170, 212,   5,   2, 254,  24,\n",
              "         90,   2, 251,  33,  80, 116, 256,  50,  23,  24, 179,   2, 180,   7,\n",
              "         27,  28,  41,  23,  24, 257,  93,   2,   6, 258,  30, 136, 259, 140,\n",
              "         30, 123,  65,  86, 179, 149,  27,   2, 260,  35,  33,  45,  90,  17,\n",
              "        177,  24, 179,   7,  27, 260,  35, 142, 151, 152, 132,  22, 179,   8,\n",
              "          2, 261, 108,  30,  23, 219, 262, 252, 253,   5,  17,  75,  27,  76,\n",
              "          3,  30,   4, 263, 264, 252, 253,  33,   5,  24, 265, 262, 252, 253,\n",
              "        266,  81, 267, 252, 268,  30,  36,  44, 269, 268,  22, 270, 271, 174,\n",
              "          8, 262, 272,  97, 273, 274,  30,  36,  85,  22,  80, 275,  24, 141,\n",
              "         76,   6, 248,   8, 276,  78,  86, 136, 277,  22,  45,  46, 278,  30,\n",
              "         68,   5,   4, 263, 264, 252, 253, 280,  95, 282,  95, 158, 283, 284,\n",
              "        176, 286, 287, 288])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,X,y):\n",
        "    self.X=X\n",
        "    self.y=y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.X[index],self.y[index]"
      ],
      "metadata": {
        "id": "N4qdCLAjjb6D"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=CustomDataset(X,y)"
      ],
      "metadata": {
        "id": "6IYsqxd7j7ki"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU6xEC5bj_Ip",
        "outputId": "4e248238-30cb-4c95-f666-ac4ef342af54"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "942"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader=DataLoader(dataset,batch_size=32,shuffle=True)"
      ],
      "metadata": {
        "id": "Jl_lWFdOkBYR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input,output in dataloader:\n",
        "  print(input,output)\n",
        "  # print(len(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTybgugYkHf5",
        "outputId": "4af270c2-1e9f-4db6-955c-0f131e4c2cbd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0,   0,   0,  ...,  20,  21,  22],\n",
            "        [  0,   0,   0,  ...,  12,  13,  14],\n",
            "        [  0,   0,   0,  ...,  38,  15,  22],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 100,   2, 131],\n",
            "        [  0,   0,   0,  ...,   9,  10,  11],\n",
            "        [  0,   0,   0,  ...,  31,   6,   7]]) tensor([ 23,  15,  45,   9, 176,  32, 135,  45,  86, 152, 219,  44, 223, 184,\n",
            "        146, 176,  30, 142,   1,   2,  57, 147,  45,  65, 252, 269,   2,  23,\n",
            "         33,  95,   3,  37])\n",
            "tensor([[  0,   0,   0,  ...,  34,  40,  28],\n",
            "        [  0,   0,   0,  ...,  69,  70,  50],\n",
            "        [  0,   0,   0,  ...,   0,   0, 139],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 135,  44,  23],\n",
            "        [  0,   0,   0,  ..., 153,   2, 154],\n",
            "        [  0,   0,   0,  ..., 224, 191, 225]]) tensor([ 41,  71,  78, 146, 249,   2, 126,  20,  78,  73,   5,   2,  86,   8,\n",
            "         24, 131,  31,  43, 184, 163,   2,  30, 262,   2,  86, 127,  95,   2,\n",
            "        206,  24,  33, 200])\n",
            "tensor([[  0,   0,   0,  ..., 175,  78,   4],\n",
            "        [  0,   0,   0,  ...,   0,  22,  23],\n",
            "        [  0,   0,   0,  ...,  65,  86, 215],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 285, 176, 286],\n",
            "        [  0,   0,   0,  ...,  86, 136, 205],\n",
            "        [  0,   0,   0,  ...,  28,  41,  93]]) tensor([208,  24,   2, 283,  22,  27,   2,   2, 262,  73,  11, 209, 259,  27,\n",
            "         50, 126,  36,  17,  69, 115,  15,  24,   2, 251,  65,   2,   8,   2,\n",
            "        131, 287, 206, 165])\n",
            "tensor([[  0,   0,   0,  ...,  68,   5,   4],\n",
            "        [  0,   0,   0,  ...,   0,   0,  95],\n",
            "        [  0,   0,   0,  ...,  22,  45,  46],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 142,   2, 143],\n",
            "        [  0,   0,   0,  ...,  19, 176, 223],\n",
            "        [  0,   0,   0,  ...,  37,  38,  39]]) tensor([263, 158, 146, 183,  64, 190,  78, 177, 179, 236,  76, 218,  76, 253,\n",
            "         18, 275,   2,   5, 171, 154, 149, 257, 202, 174,  12, 193,  95, 213,\n",
            "        110,  78, 186,  34])\n",
            "tensor([[  0,   0,   0,  ...,  85,  86,  87],\n",
            "        [  0,   0,   0,  ...,   2,   6,   5],\n",
            "        [  0,   0,   0,  ...,  30,  68,   5],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  24, 179,   2],\n",
            "        [  0,   0,   0,  ...,   2,  31,   6],\n",
            "        [  0,   0,   0,  ...,  65, 126, 164]]) tensor([ 17,  34,   4,   7,  86, 195, 172,  20,  46, 286, 136,  46, 140,   2,\n",
            "         33,  27, 125,   2,  22, 151,  86,  24, 185,  33,  23,  25, 160,  63,\n",
            "        100, 180,   7, 165])\n",
            "tensor([[  0,   0,   0,  ...,  86,  23,  24],\n",
            "        [  0,   0,   0,  ...,  17, 108,  24],\n",
            "        [  0,   0,   0,  ..., 130, 131,  89],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,   2,   6],\n",
            "        [  0,   0,   0,  ..., 276,  78,  86],\n",
            "        [  0,   0,   0,  ...,  78,  22,  65]]) tensor([153, 198, 132,  94, 109,  27,  22, 129, 177,  17,  17,  81,  45, 219,\n",
            "        102, 175, 242, 142, 144,  50,   5,   8,  27, 272,  95,  24,  88, 220,\n",
            "        101,  16, 136, 141])\n",
            "tensor([[  0,   0,   0,  ..., 146,  24, 107],\n",
            "        [  0,   0,   0,  ...,   0,   0,  86],\n",
            "        [  0,   0,   0,  ..., 136,  81, 146],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 204,   2, 149],\n",
            "        [  0,   0,   0,  ...,  94, 175,  30],\n",
            "        [  0,   0,   0,  ...,  17,  89,  22]]) tensor([ 93, 136,  24,  27, 165,  94,  44, 136,  74, 245,  17,  12, 157,  30,\n",
            "         30, 209,  93, 190, 100, 100,  17, 109, 186, 212, 227, 136,  86, 144,\n",
            "         24,  30,  68,  65])\n",
            "tensor([[  0,   0,   0,  ...,   0,   0,   4],\n",
            "        [  0,   0,   0,  ..., 179, 149,  27],\n",
            "        [  0,   0,   0,  ...,  86, 136, 259],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   5,   2,   6],\n",
            "        [  0,   0,   0,  ...,   0,   0,  92],\n",
            "        [  0,   0,   0,  ...,  34, 194, 202]]) tensor([  5,   2, 140,  24,  17, 131,  30, 241,  95, 266,   2,  38, 200,  53,\n",
            "          2, 267,  86, 117, 284,  27,  10, 280, 233,  25,   2,  86,   6,  86,\n",
            "        135,   7,  78, 192])\n",
            "tensor([[  0,   0,   0,  ...,   0,   0,  61],\n",
            "        [  0,   0,   0,  ...,   0,   0,  22],\n",
            "        [  0,   0,   0,  ...,   2,   6,   7],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 108, 109, 108],\n",
            "        [  0,   0,   0,  ...,  44, 179,   2],\n",
            "        [  0,   0,   0,  ...,   0,  22,  23]]) tensor([ 59,  45,   8,  78,   5,  33,  85,   2,  25,   6, 268,  22, 243,  24,\n",
            "          7,  18,  67, 239,  89,   2, 128,   2,  90, 167, 250, 136, 142,   5,\n",
            "        166, 110, 180,  24])\n",
            "tensor([[  0,   0,   0,  ...,   0,   0,  21],\n",
            "        [  0,   0,   0,  ...,   0,   0,  65],\n",
            "        [  0,   0,   0,  ...,  65,  44, 179],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   2, 149,  30],\n",
            "        [  0,   0,   0,  ..., 123,  65,  86],\n",
            "        [  0,   0,   0,  ...,  22,  45,  90]]) tensor([ 65,  86,   2,   2,  43,  33,  78, 121, 207,  34, 200,  25,   2,  86,\n",
            "        142,  90,   9, 179,  91,  80,  85,   2,  30,  17,  46,   8, 147,  12,\n",
            "         70,  36, 179,  17])\n",
            "tensor([[  0,   0,   0,  ...,   1,   2, 125],\n",
            "        [  0,   0,   0,  ...,  78,  22,  23],\n",
            "        [  0,   0,   0,  ...,   0,   0,  85],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  80,  96,  78],\n",
            "        [  0,   0,   0,  ..., 156,  23,  24],\n",
            "        [  0,   0,   0,  ..., 223, 186,  24]]) tensor([102,  24,  86,  85,  72, 201,  23, 260, 179, 205, 260, 179,  22,   6,\n",
            "         97,  23, 164,  52, 253,  23,  45,   6, 211,  33,  30, 165,  33,  84,\n",
            "         45,  36, 153, 224])\n",
            "tensor([[  0,   0,   0,  ..., 234,  27,   2],\n",
            "        [  0,   0,   0,  ...,  58,  73,  74],\n",
            "        [  0,   0,   0,  ...,  93,   2, 147],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  27,   2,  11],\n",
            "        [  0,   0,   0,  ...,   0,  22,  23],\n",
            "        [  0,   0,   0,  ..., 262, 272,  97]]) tensor([235,  46, 150,  78, 136,  30,  22,  30,  93,  30,  42,   5, 166,  76,\n",
            "        146,  80,  47,  78,  22,  89,  81,  33,  41, 132, 181,  30, 183, 159,\n",
            "         17,   3,  24, 273])\n",
            "tensor([[  0,   0,   0,  ..., 176,   2, 175],\n",
            "        [  0,   0,   0,  ...,  22, 270, 271],\n",
            "        [  0,   0,   0,  ...,   0,   0, 213],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  79,  80,  81],\n",
            "        [  0,   0,   0,  ...,   2,  67,  43],\n",
            "        [  0,   0,   0,  ...,   0,   0, 169]]) tensor([ 33, 174, 214, 176,  54, 108,   2,   2,  78,   2,   8,  90,   6,  26,\n",
            "         39,  80,   2, 186,   3,  32,  50,  36, 127,  23, 142, 176,   2, 145,\n",
            "         24,  17,  68, 170])\n",
            "tensor([[  0,   0,   0,  ...,   2,   6,  69],\n",
            "        [  0,   0,   0,  ..., 104,  76, 105],\n",
            "        [  0,   0,   0,  ..., 143,  78,  45],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 265, 262, 252],\n",
            "        [  0,   0,   0,  ..., 235,   6,   7],\n",
            "        [  0,   0,   0,  ..., 248, 249, 147]]) tensor([ 70, 106,  86, 166,  19, 141, 264,  33,  33, 105, 168,  45, 112, 142,\n",
            "        174,  33,  94,  27,   8,  76,   2,  93,  30, 107,  18, 132,   9, 141,\n",
            "          2, 253,  30, 246])\n",
            "tensor([[  0,   0,   0,  ...,  21, 135,  86],\n",
            "        [  0,   0,   0,  ...,   2,   6,  16],\n",
            "        [  0,   0,   0,  ..., 142, 151, 152],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  22, 155,  82],\n",
            "        [  0,   0,   0,  ...,  65,  44, 163],\n",
            "        [  0,   0,   0,  ...,   0,   0,  86]]) tensor([ 23,  17, 132,  33, 222,   7,   6, 252, 116,  95, 176,   2,   5,  30,\n",
            "        158,   2, 148,  69,  30, 103,  78, 225,  30, 252,   5, 176,  80,   2,\n",
            "         93, 156,  22, 136])\n",
            "tensor([[  0,   0,   0,  ...,   8, 262, 272],\n",
            "        [  0,   0,   0,  ...,  95,  80,  96],\n",
            "        [  0,   0,   0,  ...,   2, 216, 213],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,   0,   2],\n",
            "        [  0,   0,   0,  ..., 154,  30,  44],\n",
            "        [  0,   0,   0,  ...,  63,  27,  17]]) tensor([ 97,  78, 151,  27,  33,  28, 221,   4,  24,  33, 149,  73,  24,  88,\n",
            "         23,  82,   0,  86, 203, 192, 135, 248,  46,   2, 156,  24,   2, 240,\n",
            "         33,   6,  45, 238])\n",
            "tensor([[  0,   0,   0,  ..., 217,   5, 218],\n",
            "        [  0,   0,   0,  ...,  50, 112,  33],\n",
            "        [  0,   0,   0,  ..., 251,  73, 252],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  24,  25,   2],\n",
            "        [  0,   0,   0,  ...,  94,  26,  33],\n",
            "        [  0,   0,   0,  ...,  74,  46,  17]]) tensor([ 78, 113, 253, 188,  24, 161,  22, 124,  75,   3,  22,  90,   2,  19,\n",
            "         94,   6, 252,  27,  35,  33,   2,   2, 111, 232,  22,  23,  86,  30,\n",
            "         30, 149, 151,  75])\n",
            "tensor([[  0,   0,   0,  ..., 191, 225, 200],\n",
            "        [  0,   0,   0,  ...,  65,  86, 135],\n",
            "        [  0,   0,   0,  ...,  33,  45,  86],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  65, 141,   2],\n",
            "        [  0,   0,   0,  ..., 200, 223, 190],\n",
            "        [  0,   0,   0,  ..., 186,  24, 224]]) tensor([223,  76,  90,  23,  35,   5,  32,  22, 151,  82, 197, 238, 105,  17,\n",
            "          2, 140,  22, 137,  63,  86,  17, 168, 274,  46, 142,  89,  74, 175,\n",
            "        175,   3,  22, 191])\n",
            "tensor([[  0,   0,   0,  ..., 195,  22,  25],\n",
            "        [  0,   0,   0,  ...,   0, 182,  77],\n",
            "        [  0,   0,   0,  ...,   2, 175,  78],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  27, 260,  35],\n",
            "        [  0,   0,   0,  ...,  87,  17,  88],\n",
            "        [  0,   0,   0,  ...,   5, 193, 194]]) tensor([  2,  78,   4, 133, 131,  94, 256, 189,  50, 207,  46,   3,  30,   2,\n",
            "         19,  36,   8,  85, 252, 156,  10,   2, 146, 108,  98,  24,  34, 263,\n",
            "        258, 142,  89, 127])\n",
            "tensor([[  0,   0,   0,  ..., 155,  82, 156],\n",
            "        [  0,   0,   0,  ...,   2,  31,  32],\n",
            "        [  0,   0,   0,  ...,  55,   8,   9],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  22,  45,  23],\n",
            "        [  0,   0,   0,  ...,  24, 153,   2],\n",
            "        [  0,   0,   0,  ...,  26, 176,  94]]) tensor([199,  27,  10,  86,  41,  17, 107,  16, 149,  65, 188,  86,   5,   2,\n",
            "         24,  78, 212,  65, 216,   2,  65,   3,   3, 131,  44,  22,  96, 138,\n",
            "         28,  24, 154, 175])\n",
            "tensor([[  0,   0,   0,  ...,  46,  47,   2],\n",
            "        [  0,   0,   0,  ...,   0,   0,   4],\n",
            "        [  0,   0,   0,  ..., 220,  30,  22],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 252, 268,  30],\n",
            "        [  0,   0,   0,  ...,  32,  27,   2],\n",
            "        [  0,   0,   0,  ...,   0,   0,   4]]) tensor([ 48,   5,  65,  17,  77,  70,  93,  44,  65,  30,  33,  11, 135,  45,\n",
            "         73,  33, 163,  25, 246,  30,  27, 261,  13,  73, 163,  22,  65, 130,\n",
            "        134,  36,   6,   5])\n",
            "tensor([[  0,   0,   0,  ...,  39,  34,  40],\n",
            "        [  0,   0,   0,  ..., 160, 161,   2],\n",
            "        [  0,   0,   0,  ..., 142, 151, 152],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,  45,  44],\n",
            "        [  0,   0,   0,  ...,  63,  64, 142],\n",
            "        [  0,   0,   0,  ...,  18,  19,  20]]) tensor([ 28, 154,  73, 141,  79,  82,   3, 268,  72, 173,   2, 243,  95, 152,\n",
            "         82, 176,   2, 202,  23, 175, 238,  93, 175, 127,  33, 151,  75, 131,\n",
            "        215, 135,   2,  21])\n",
            "tensor([[  0,   0,   0,  ..., 269, 268,  22],\n",
            "        [  0,   0,   0,  ...,   0,   0, 281],\n",
            "        [  0,   0,   0,  ..., 139,  78,  22],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  73, 252, 253],\n",
            "        [  0,   0,   0,  ...,   0,   0, 234],\n",
            "        [  0,   0,   0,  ..., 245, 147, 246]]) tensor([270, 282,  65,  45,  69,  27,   2, 174,  24,  24,  58,  89, 176,  64,\n",
            "        244, 226,  27, 149,  30,   5,   4, 213,  30,   6, 205, 155,  58, 126,\n",
            "        187, 170,  27, 247])\n",
            "tensor([[  0,   0,   0,  ...,  25,   2, 149],\n",
            "        [  0,   0,   0,  ...,  92,  93,  94],\n",
            "        [  0,   0,   0,  ...,   0,   0,  86],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 248,   8, 276],\n",
            "        [  0,   0,   0,  ...,   2, 102, 103],\n",
            "        [  0,   0,   0,  ...,   2,   6, 258]]) tensor([176,  95,  23,  22,  86,   4,  33,   2,  33, 152,  24,   6, 216,   2,\n",
            "         78, 123, 119, 264, 238,  89, 179,  24,  33,  30,  68,  45,  23, 252,\n",
            "         73,  78,  33,  30])\n",
            "tensor([[  0,   0,   0,  ..., 145, 142,   2],\n",
            "        [  0,   0,   0,  ...,  12, 174,  34],\n",
            "        [  0,   0,   0,  ..., 225, 200, 223],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  82,  83,  84],\n",
            "        [  0,   0,   0,  ..., 206, 207,  73],\n",
            "        [  0,   0,   0,  ...,  27,   2, 260]]) tensor([143, 228, 190, 208,  38,  33,  81,   2, 194,  22,   2,  22,  30,  18,\n",
            "         93,  50,  65,  23, 195, 135,  19, 248,  81, 271,  23,  27, 196, 155,\n",
            "        151,  30,  86,  35])\n",
            "tensor([[  0,   0,   0,  ...,   8,   2, 261],\n",
            "        [  0,   0,   0,  ...,  64, 142,   2],\n",
            "        [  0,   0,   0,  ..., 132,  22, 179],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  23,  24, 163],\n",
            "        [  0,   0,   0,  ...,  23, 131, 164],\n",
            "        [  0,   0,   0,  ...,  97,  85,  22]]) tensor([108,   3,   8, 185,   5,   5,   2, 191,   6,  24, 149,  58, 109, 141,\n",
            "        204,  25,  94,  86,  33, 223,  85,  22, 109,  87, 237,  44,  46,  30,\n",
            "        116, 164,  28,  87])\n",
            "tensor([[  0,   0,   0,  ..., 176, 286, 287],\n",
            "        [  0,   0,   0,  ...,   0,  92,  78],\n",
            "        [  0,   0,   0,  ...,  24,  25,  94],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  38,  39,  34],\n",
            "        [  0,   0,   0,  ...,  78, 248, 249],\n",
            "        [  0,   0,   0,  ...,  78,  36,  97]]) tensor([288, 139,  26,  25,   2,  66,  30,  23, 167, 217, 132,  78, 147,   2,\n",
            "         30, 194, 162,  27, 164,  31, 149,  23,  27, 146,  17, 118,   2,  26,\n",
            "         45,  40, 147,  85])\n",
            "tensor([[  0,   0,   0,  ...,  78,  86, 136],\n",
            "        [  0,   0,   0,  ...,   0, 185, 191],\n",
            "        [  0,   0,   0,  ...,  30,  68,   5],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 131,  89, 132],\n",
            "        [  0,   0,   0,  ...,  82, 156,  23],\n",
            "        [  0,   0,   0,  ...,   0,   0,  21]]) tensor([277,   2,   2,  30,  33,  30, 167, 242,  49,   2,   5,  29,  18,  60,\n",
            "        135, 143,  86,  22,  28,  83, 105,   2,  33,  22,  19,  45,   3, 192,\n",
            "        178,  22,  24,  65])\n",
            "tensor([[  0,   0,   0,  ..., 100,  93,   2],\n",
            "        [  0,   0,   0,  ...,   5,  24, 265],\n",
            "        [  0,   0,   0,  ...,  45,  90,  17],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 119, 109,   2],\n",
            "        [  0,   0,   0,  ...,   5, 227,  73],\n",
            "        [  0,   0,   0,  ...,  46, 146,  24]]) tensor([147, 262, 126, 183,  44,  99, 229,  93,  86,  33,  41, 155,   2,   2,\n",
            "        265,  73,   5,  28,  22,  31, 253,  81,   2,  76, 276, 278, 164, 240,\n",
            "         27, 120,  22, 107])\n",
            "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,  51,  53],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   4,   5,   2],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,  76, 217,   5, 218,  78,\n",
            "          36, 219, 220,  30,  22,  65, 100,   2, 216, 213, 151,  19,   5, 221,\n",
            "          30, 184,  22,  23, 222],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  86, 136, 140,  78,\n",
            "          65,  86, 141,   2,   3],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,  21,  65,  44],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   4,   5,   2,   6,   7,   8,   9,\n",
            "          10,  11,   3,  12,  13],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          92,  93,  94,  95,  80,  96,  78,  36,  97,  85,  22,  87,  17,  89,\n",
            "          22,  65,  98,  99,  73],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   4,   5,   2, 183,  27,  18,\n",
            "          19,  33, 184,  85,  86],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  65,  86, 135,  76,\n",
            "           6,  85,  86, 136, 127],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,  92,  93,  94,  95,  80,  96,  78,\n",
            "          36,  97,  85,  22,  87],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  92,  93,\n",
            "          94,  95,  80,  96,  78,  36,  97,  85,  22,  87,  17,  89,  22,  65,\n",
            "          98,  99,  73, 100,   2],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   2,  31,  32,  27,   2,   6,\n",
            "           5,  34,  35,  30,  36,   2,  31,   6,   7,  37,  38,  39,  34,  40,\n",
            "          28,  41,  12,  42,  30],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         231, 232, 183,   5,  81],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0, 185, 191,   2, 183, 192,   5, 193, 194, 127,   2, 195,  22,\n",
            "          25,   2, 149,  30,  36, 196,  22,  65, 141, 144,  22, 155,  82, 156,\n",
            "          23,  24, 197,   8,  17]]) tensor([  8, 254,  19, 142, 163,  14, 100, 179,  17,  17,  91,  15, 233, 108])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "  def __init__(self,vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(vocab_size,100)\n",
        "    self.lstm=nn.LSTM(100,150,batch_first=True)\n",
        "    self.fc=nn.Linear(150,vocab_size)\n",
        "\n",
        "  def forward(self,x):\n",
        "    embedded=self.embedding(x)\n",
        "    intermediate_hidden_states,(final_hidden_state,final_cell_state)=self.lstm(embedded)\n",
        "    output=self.fc(final_hidden_state.squeeze(0))\n",
        "    return output"
      ],
      "metadata": {
        "id": "aP-B4QIykMBp"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=LSTMModel(len(vocab))"
      ],
      "metadata": {
        "id": "WBWR2Y7slKMn"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4GFeCjclNqW",
        "outputId": "37e4b4e6-6541-4dd6-8e3b-794937fea581"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWTTpgWalVU1",
        "outputId": "792ffd3a-d875-47d3-b035-04e9620dc4d8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(289, 100)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=289, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=50\n",
        "learning_rate=0.001\n",
        "\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "FQ2EYE02lZK1"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  total_loss=0\n",
        "\n",
        "  for batch_x,batch_y in dataloader:\n",
        "    batch_x,batch_y=batch_x.to(device),batch_y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output=model(batch_x)\n",
        "\n",
        "    loss=criterion(output,batch_y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss+=loss.item()\n",
        "\n",
        "  print(f\"Epoch: {epoch + 1}, Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hccfNbwol8CM",
        "outputId": "1b5d317a-e58b-4dbb-d4f0-818a71792358"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 4.4392\n",
            "Epoch: 2, Loss: 4.2579\n",
            "Epoch: 3, Loss: 4.1943\n",
            "Epoch: 4, Loss: 4.2150\n",
            "Epoch: 5, Loss: 4.0637\n",
            "Epoch: 6, Loss: 4.4434\n",
            "Epoch: 7, Loss: 3.9852\n",
            "Epoch: 8, Loss: 4.0692\n",
            "Epoch: 9, Loss: 4.0526\n",
            "Epoch: 10, Loss: 3.9160\n",
            "Epoch: 11, Loss: 3.8657\n",
            "Epoch: 12, Loss: 3.8209\n",
            "Epoch: 13, Loss: 3.7651\n",
            "Epoch: 14, Loss: 3.6998\n",
            "Epoch: 15, Loss: 3.7533\n",
            "Epoch: 16, Loss: 3.8084\n",
            "Epoch: 17, Loss: 3.7114\n",
            "Epoch: 18, Loss: 3.7549\n",
            "Epoch: 19, Loss: 3.6700\n",
            "Epoch: 20, Loss: 3.7135\n",
            "Epoch: 21, Loss: 3.7623\n",
            "Epoch: 22, Loss: 3.5722\n",
            "Epoch: 23, Loss: 3.4426\n",
            "Epoch: 24, Loss: 3.5149\n",
            "Epoch: 25, Loss: 3.5820\n",
            "Epoch: 26, Loss: 3.4755\n",
            "Epoch: 27, Loss: 3.4420\n",
            "Epoch: 28, Loss: 3.4845\n",
            "Epoch: 29, Loss: 3.3872\n",
            "Epoch: 30, Loss: 3.4678\n",
            "Epoch: 31, Loss: 3.6138\n",
            "Epoch: 32, Loss: 3.4410\n",
            "Epoch: 33, Loss: 3.3326\n",
            "Epoch: 34, Loss: 3.5772\n",
            "Epoch: 35, Loss: 3.4831\n",
            "Epoch: 36, Loss: 3.5753\n",
            "Epoch: 37, Loss: 3.2904\n",
            "Epoch: 38, Loss: 3.3820\n",
            "Epoch: 39, Loss: 3.3760\n",
            "Epoch: 40, Loss: 3.3256\n",
            "Epoch: 41, Loss: 3.3752\n",
            "Epoch: 42, Loss: 3.1999\n",
            "Epoch: 43, Loss: 3.2086\n",
            "Epoch: 44, Loss: 3.3691\n",
            "Epoch: 45, Loss: 3.2222\n",
            "Epoch: 46, Loss: 3.2180\n",
            "Epoch: 47, Loss: 3.1138\n",
            "Epoch: 48, Loss: 3.2088\n",
            "Epoch: 49, Loss: 3.2425\n",
            "Epoch: 50, Loss: 3.2949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(model,vocab,text):\n",
        "\n",
        "  tokenized_text=word_tokenize(text.lower())\n",
        "\n",
        "  numerical_text=text_to_indices(tokenized_text,vocab)\n",
        "\n",
        "  padded_text = torch.tensor([0] * (61 - len(numerical_text)) + numerical_text, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "  output=model(padded_text)\n",
        "\n",
        "  value,index=torch.max(output,dim=1)\n",
        "\n",
        "  return text + \" \" + list(vocab.keys())[index]"
      ],
      "metadata": {
        "id": "laRxmYhImcPT"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(model,vocab,\"The course follows a monthly\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ahTbER9Lnh5A",
        "outputId": "28e9ca07-9b70-4013-cf82-6ca2e7fe1f16"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The course follows a monthly subscription'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "num_tokens=10\n",
        "input_text=\"hi how are\"\n",
        "\n",
        "for i in range(num_tokens):\n",
        "  output_text=prediction(model,vocab,input_text)\n",
        "  print(output_text)\n",
        "  input_text=output_text\n",
        "  time.sleep(0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P-qf2cCnyza",
        "outputId": "391d998b-1be7-4270-b947-58313840fad4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi how are the\n",
            "hi how are the program\n",
            "hi how are the program follows\n",
            "hi how are the program follows a\n",
            "hi how are the program follows a monthly\n",
            "hi how are the program follows a monthly subscription\n",
            "hi how are the program follows a monthly subscription model\n",
            "hi how are the program follows a monthly subscription model .\n",
            "hi how are the program follows a monthly subscription model . you\n",
            "hi how are the program follows a monthly subscription model . you have\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader1=DataLoader(dataset,batch_size=1,shuffle=True)"
      ],
      "metadata": {
        "id": "82744BK2pnV8"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(model,dataloader,device):\n",
        "  # set model for evaluation\n",
        "  model.eval()\n",
        "  correct=0\n",
        "  total=0\n",
        "  # no need to compute gradients\n",
        "  with torch.no_grad():\n",
        "    for batch_x,batch_y in dataloader1:\n",
        "      batch_x=batch_x.to(device)\n",
        "      batch_y=batch_y.to(device)\n",
        "\n",
        "      # get model prediction\n",
        "      outputs=model(batch_x)\n",
        "\n",
        "      # get the predicted word indices\n",
        "      _, predicted=torch.max(outputs,dim=1)\n",
        "\n",
        "      # compare with actual labels\n",
        "      correct+=(predicted==batch_y).sum().item()\n",
        "      total+=batch_y.size(0)\n",
        "\n",
        "  accuracy=correct/total * 100\n",
        "  return accuracy\n",
        "\n",
        "accuracy = calculate_accuracy(model, dataloader, device)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-QzshDRn0B3",
        "outputId": "45fd7339-4c3c-47cc-d8d6-2848da45299d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 95.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cpkf5b-2qav4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}